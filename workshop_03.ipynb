{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Workshop 03: Machine Learning Models for Industrial Safety\n",
        "This notebook loads the Kaggle dataset 'Industrial Safety and Health Analytics Database', performs EDA (Exploratory Data Analysis) and Data Quality checks, and applies two Supervised Machine Learning algorithms (Random Forest and Logistic Regression) to predict the accident level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_theme(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carga de Datos\n",
        "We load the dataset using `kagglehub`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install kagglehub if not present\n",
        "!pip install -q kagglehub\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"ihmstefanini/industrial-safety-and-health-analytics-database\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Load the dataset\n",
        "csv_file = os.path.join(path, \"IHMStefanini_industrial_safety_and_health_database.csv\")\n",
        "df = pd.read_csv(csv_file)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Calidad de data (Nulos)\n",
        "Verificando la calidad de data. Determinando si hay nulos en nuestro dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Valores nulos por columna:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Eliminar filas con nulos en variables clave (si los hubiera)\n",
        "features = ['Countries', 'Local', 'Industry Sector', 'Genre', 'Employee ou Terceiro', 'Risco Critico']\n",
        "target = 'Accident Level'\n",
        "df = df.dropna(subset=features + [target])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Analizando datos por variable (Univariado)\n",
        "Visualizando la distribución de las variables más importantes de forma individual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.countplot(y=\"Industry Sector\", data=df, order=df['Industry Sector'].value_counts().index)\n",
        "plt.title(\"Distribución por Sector Industrial\")\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.countplot(x=\"Accident Level\", data=df, order=['I', 'II', 'III', 'IV', 'V', 'VI'], palette=\"Reds\")\n",
        "plt.title(\"Distribución del Nivel de Accidente (Target)\")\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "sns.countplot(x=\"Genre\", data=df, palette=\"pastel\")\n",
        "plt.title(\"Distribución por Género\")\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "sns.countplot(x=\"Employee ou Terceiro\", data=df, palette=\"Set2\")\n",
        "plt.title(\"Distribución por Tipo de Empleado\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Análisis de variables en conjunto (Bivariado)\n",
        "Relacionando las variables independientes con nuestra variable objetivo (`Accident Level`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x=\"Industry Sector\", hue=\"Accident Level\", data=df, \n",
        "              hue_order=['I', 'II', 'III', 'IV', 'V', 'VI'], palette=\"Reds\")\n",
        "plt.title(\"Nivel de Accidente según el Sector Industrial\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x=\"Employee ou Terceiro\", hue=\"Accident Level\", data=df, \n",
        "              hue_order=['I', 'II', 'III', 'IV', 'V', 'VI'], palette=\"Reds\")\n",
        "plt.title(\"Nivel de Accidente según el Tipo de Empleado (Propio vs Tercero)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Pre-procesamiento de Datos\n",
        "Preparar los datos para los modelos de Machine Learning (Supervisado)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Dividir los datos (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Dimensiones de entrenamiento: {X_train.shape}\")\n",
        "print(f\"Dimensiones de prueba: {X_test.shape}\")\n",
        "\n",
        "# Transformador para convertir variables de texto a números (One-Hot Encoding)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), features)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Aplicando Algoritmos (Machine Learning Supervisado)\n",
        "Vamos a aplicar los dos algoritmos elegidos: Random Forest y Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Modelo 1: Bosques Aleatorios (Random Forest) ---\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))\n",
        "])\n",
        "\n",
        "rf_pipeline.fit(X_train, y_train)\n",
        "rf_predictions = rf_pipeline.predict(X_test)\n",
        "\n",
        "print(\"--- Resultados de Random Forest ---\")\n",
        "print(f\"Precisión (Accuracy): {accuracy_score(y_test, rf_predictions):.4f}\")\n",
        "print(\"Reporte de Clasificación:\")\n",
        "print(classification_report(y_test, rf_predictions, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Modelo 2: Regresión Logística Multinomial ---\n",
        "lr_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=42, max_iter=1000, multi_class='multinomial'))\n",
        "])\n",
        "\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "lr_predictions = lr_pipeline.predict(X_test)\n",
        "\n",
        "print(\"--- Resultados de Regresión Logística ---\")\n",
        "print(f\"Precisión (Accuracy): {accuracy_score(y_test, lr_predictions):.4f}\")\n",
        "print(\"Reporte de Clasificación:\")\n",
        "print(classification_report(y_test, lr_predictions, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Asignando modelo a cada incidente (Predicción Final)\n",
        "Mostrando las predicciones del mejor modelo (Random Forest) junto a los datos originales de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar los resultados en el dataframe de prueba para visualizarlos\n",
        "resultados = X_test.copy()\n",
        "resultados['Nivel Real (Target)'] = y_test\n",
        "resultados['Nivel Predicho (RF)'] = rf_predictions\n",
        "\n",
        "print(\"Resultados de la asignación del modelo (Predicciones vs Realidad):\")\n",
        "resultados.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
