{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Workshop 03: Machine Learning Models for Industrial Safety\n",
        "This notebook loads the Kaggle dataset 'Industrial Safety and Health Analytics Database', preprocesses the data, and applies two classification algorithms (Random Forest and Logistic Regression) to predict the accident level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n",
        "We can load the dataset directly using `kagglehub`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install kagglehub if not present\n",
        "!pip install -q kagglehub\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"ihmstefanini/industrial-safety-and-health-analytics-database\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Load the dataset\n",
        "import os\n",
        "csv_file = os.path.join(path, \"IHMStefanini_industrial_safety_and_health_database.csv\")\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preprocessing\n",
        "Select relevant features and split into X and y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining Features (X) and Target (y)\n",
        "features = ['Countries', 'Local', 'Industry Sector', 'Genre', 'Employee ou Terceiro', 'Risco Critico']\n",
        "target = 'Accident Level'\n",
        "\n",
        "# Drop rows with missing target or features just in case\n",
        "df = df.dropna(subset=features + [target])\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Split data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training dimensions: {X_train.shape}\")\n",
        "print(f\"Test dimensions: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Modeling Pipeline\n",
        "Create preprocessing steps to One-Hot Encode categorical features, and train the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessor: One-Hot Encoding for categorical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), features)\n",
        "    ])\n",
        "\n",
        "# --- Model 1: Random Forest Classifier ---\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))\n",
        "])\n",
        "\n",
        "# Train Random Forest\n",
        "rf_pipeline.fit(X_train, y_train)\n",
        "rf_predictions = rf_pipeline.predict(X_test)\n",
        "\n",
        "print(\"--- Random Forest Results ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, rf_predictions):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, rf_predictions, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Model 2: Logistic Regression (Multinomial) ---\n",
        "lr_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=42, max_iter=1000, multi_class='multinomial'))\n",
        "])\n",
        "\n",
        "# Train Logistic Regression\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "lr_predictions = lr_pipeline.predict(X_test)\n",
        "\n",
        "print(\"--- Logistic Regression Results ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, lr_predictions):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, lr_predictions, zero_division=0))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
